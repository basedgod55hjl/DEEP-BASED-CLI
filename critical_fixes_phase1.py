#!/usr/bin/env python3
"""
Critical Fixes Phase 1 - Implementing AI Swarm Recommendations
Automated fixes for the most critical issues identified by the 190 AI agent swarm
"""

import os
import sys
import re
import ast
import logging
from pathlib import Path
from typing import List, Dict, Any, Tuple
from dataclasses import dataclass
import shutil
from datetime import datetime

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class FixResult:
    """Result of applying a fix"""
    file_path: str
    fix_type: str
    success: bool
    changes_made: int
    error_message: str = ""

class CriticalFixer:
    """Implements critical fixes identified by AI swarm analysis"""
    
    def __init__(self, codebase_path: str = "."):
    """__init__ function."""
        self.codebase_path = Path(codebase_path)
        self.backup_dir = Path("backups/critical_fixes")
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        self.fix_results = []
        
    def create_backup(self, file_path: Path) -> Path:
        """Create backup of original file"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"{file_path.stem}_{timestamp}{file_path.suffix}"
        backup_path = self.backup_dir / backup_name
        
        try:
            shutil.copy2(file_path, backup_path)
            logger.info(f"Created backup: {backup_path}")
            return backup_path
        except Exception as e:
            logger.error(f"Failed to create backup for {file_path}: {e}")
            return None
    
    def fix_bare_exceptions(self, file_path: Path) -> FixResult:
        """Fix bare except clauses by replacing with specific exception types"""
        try:
            # Create backup
            backup_path = self.create_backup(file_path)
            if not backup_path:
                return FixResult(str(file_path), "bare_exceptions", False, 0, "Backup creation failed")
            
            # Read file
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            original_content = content
            changes_made = 0
            
            # Find and replace bare except clauses
            # Pattern: except Exception: or except Exception:
            patterns = [
                (r'except\s*:', r'except Exception:'),
                (r'except\s*:\s*#', r'except Exception:  #'),
                (r'except\s*:\s*"""', r'except Exception:  """'),
                (r'except\s*:\s*"""', r'except Exception:  """'),
            ]
            
            for pattern, replacement in patterns:
                matches = re.findall(pattern, content)
                if matches:
                    content = re.sub(pattern, replacement, content)
                    changes_made += len(matches)
            
            # Write back if changes were made
            if changes_made > 0:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                logger.info(f"Fixed {changes_made} bare exception clauses in {file_path}")
                return FixResult(str(file_path), "bare_exceptions", True, changes_made)
            else:
                return FixResult(str(file_path), "bare_exceptions", True, 0)
                
        except Exception as e:
            logger.error(f"Error fixing bare exceptions in {file_path}: {e}")
            return FixResult(str(file_path), "bare_exceptions", False, 0, str(e))
    
    def fix_print_statements(self, file_path: Path) -> FixResult:
        """Replace print statements with proper logging"""
        try:
            # Create backup
            backup_path = self.create_backup(file_path)
            if not backup_path:
                return FixResult(str(file_path), "print_statements", False, 0, "Backup creation failed")
            
            # Read file
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            original_content = content
            changes_made = 0
            
            # Check if logging is already imported
            has_logging_import = 'import logging' in content or 'from logging import' in content
            
            # Add logging import if not present
            if not has_logging_import and 'print(' in content:
                # Find the first import statement
                import_match = re.search(r'^(import\s+\w+|from\s+\w+\s+import)', content, re.MULTILINE)
                if import_match:
                    # Add logging import after existing imports
                    logging_import = "import logging\n"
                    content = content[:import_match.end()] + "\n" + logging_import + content[import_match.end():]
                    changes_made += 1
                else:
                    # Add at the beginning
                    content = "import logging\n\n" + content
                    changes_made += 1
            
            # Replace print statements with logging
            # Pattern: logging.info(...)
            print_pattern = r'print\s*\((.*?)\)'
            
            def replace_logging.info(match):
                args = match.group(1).strip()
                if args.startswith('"') or args.startswith("'"):
                    # String literal
                    return f'logging.info({args})'
                else:
                    # Variable or expression
                    return f'logging.info({args})'
            
            print_matches = re.findall(print_pattern, content)
            if print_matches:
                content = re.sub(print_pattern, replace_print, content)
                changes_made += len(print_matches)
            
            # Write back if changes were made
            if changes_made > 0:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                logger.info(f"Fixed {changes_made} print statements in {file_path}")
                return FixResult(str(file_path), "print_statements", True, changes_made)
            else:
                return FixResult(str(file_path), "print_statements", True, 0)
                
        except Exception as e:
            logger.error(f"Error fixing print statements in {file_path}: {e}")
            return FixResult(str(file_path), "print_statements", False, 0, str(e))
    
    def fix_wildcard_imports(self, file_path: Path) -> FixResult:
        """Replace wildcard imports with specific imports"""
        try:
            # Create backup
            backup_path = self.create_backup(file_path)
            if not backup_path:
                return FixResult(str(file_path), "wildcard_imports", False, 0, "Backup creation failed")
            
            # Read file
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            original_content = content
            changes_made = 0
            
            # Find wildcard imports
            wildcard_pattern = r'from\s+(\w+(?:\.\w+)*)\s+import\s+\*'
            wildcard_matches = re.findall(wildcard_pattern, content)
            
            if wildcard_matches:
                # Replace with common specific imports
                replacements = {
                    'os': 'from os import path, environ, makedirs, listdir',
                    'sys': 'from sys import path, argv, exit',
                    'typing': 'from typing import List, Dict, Any, Optional, Tuple',
                    'datetime': 'from datetime import datetime, timedelta',
                    'json': 'from json import loads, dumps',
                    'logging': 'from logging import info, warning, error, debug',
                }
                
                for module in wildcard_matches:
                    if module in replacements:
                        old_import = f'from {module} import *'
                        new_import = replacements[module]
                        content = content.replace(old_import, new_import)
                        changes_made += 1
            
            # Write back if changes were made
            if changes_made > 0:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                logger.info(f"Fixed {changes_made} wildcard imports in {file_path}")
                return FixResult(str(file_path), "wildcard_imports", True, changes_made)
            else:
                return FixResult(str(file_path), "wildcard_imports", True, 0)
                
        except Exception as e:
            logger.error(f"Error fixing wildcard imports in {file_path}: {e}")
            return FixResult(str(file_path), "wildcard_imports", False, 0, str(e))
    
    def add_type_hints(self, file_path: Path) -> FixResult:
        """Add type hints to functions that don't have them"""
        try:
            # Create backup
            backup_path = self.create_backup(file_path)
            if not backup_path:
                return FixResult(str(file_path), "type_hints", False, 0, "Backup creation failed")
            
            # Read file
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            original_content = content
            changes_made = 0
            
            # Check if typing is imported
            has_typing_import = 'import typing' in content or 'from typing import' in content
            
            # Add typing import if not present
            if not has_typing_import:
                import_match = re.search(r'^(import\s+\w+|from\s+\w+\s+import)', content, re.MULTILINE)
                if import_match:
                    typing_import = "from typing import List, Dict, Any, Optional, Tuple\n"
                    content = content[:import_match.end()] + "\n" + typing_import + content[import_match.end():]
                    changes_made += 1
                else:
                    content = "from typing import List, Dict, Any, Optional, Tuple\n\n" + content
                    changes_made += 1
            
            # Find function definitions without type hints
            # Pattern: def function_name(parameters) -> Any:
            func_pattern = r'def\s+(\w+)\s*\(([^)]*)\)\s*:'
            
            def add_type_hint_to_func(match) -> Any:
                func_name = match.group(1)
                params = match.group(2)
                
                # Skip if already has type hints
                if '->' in params or ':' in params:
                    return match.group(0)
                
                # Add basic type hints
                if not params.strip():
                    return f'def {func_name}() -> None:'
                else:
                    # Add -> Any for now (can be improved later)
                    return f'def {func_name}({params}) -> Any:'
            
            func_matches = re.findall(func_pattern, content)
            if func_matches:
                content = re.sub(func_pattern, add_type_hint_to_func, content)
                changes_made += len(func_matches)
            
            # Write back if changes were made
            if changes_made > 0:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                logger.info(f"Added type hints to {changes_made} functions in {file_path}")
                return FixResult(str(file_path), "type_hints", True, changes_made)
            else:
                return FixResult(str(file_path), "type_hints", True, 0)
                
        except Exception as e:
            logger.error(f"Error adding type hints to {file_path}: {e}")
            return FixResult(str(file_path), "type_hints", False, 0, str(e))
    
    def add_docstrings(self, file_path: Path) -> FixResult:
        """Add docstrings to functions that don't have them"""
        try:
            # Create backup
            backup_path = self.create_backup(file_path)
            if not backup_path:
                return FixResult(str(file_path), "docstrings", False, 0, "Backup creation failed")
            
            # Read file
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            original_content = content
            changes_made = 0
            
            # Find function definitions
            func_pattern = r'def\s+(\w+)\s*\(([^)]*)\)\s*:'
            
            def add_docstring_to_func(match) -> Any:
                func_name = match.group(1)
                params = match.group(2)
                
                # Get the function body
                func_start = match.end()
                lines = content[func_start:].split('\n')
                
                # Check if next line is already a docstring
                if lines and (lines[0].strip().startswith('"""') or lines[0].strip().startswith("'''")):
                    return match.group(0)
                
                # Add simple docstring
                docstring = f'\n    """{func_name} function."""'
                return match.group(0) + docstring
            
            func_matches = re.findall(func_pattern, content)
            if func_matches:
                content = re.sub(func_pattern, add_docstring_to_func, content)
                changes_made += len(func_matches)
            
            # Write back if changes were made
            if changes_made > 0:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                logger.info(f"Added docstrings to {changes_made} functions in {file_path}")
                return FixResult(str(file_path), "docstrings", True, changes_made)
            else:
                return FixResult(str(file_path), "docstrings", True, 0)
                
        except Exception as e:
            logger.error(f"Error adding docstrings to {file_path}: {e}")
            return FixResult(str(file_path), "docstrings", False, 0, str(e))
    
    def find_python_files(self) -> List[Path]:
        """Find all Python files to process"""
        python_files = []
        for py_file in self.codebase_path.rglob("*.py"):
            if "backup" not in str(py_file) and "node_modules" not in str(py_file):
                python_files.append(py_file)
        return python_files
    
    def apply_all_fixes(self) -> Dict[str, Any]:
        """Apply all critical fixes to the codebase"""
        logger.info("ðŸš€ Starting Critical Fixes Phase 1")
        
        python_files = self.find_python_files()
        logger.info(f"Found {len(python_files)} Python files to process")
        
        total_fixes = 0
        successful_fixes = 0
        
        for file_path in python_files:
            logger.info(f"Processing {file_path}")
            
            # Apply each fix type
            fixes = [
                self.fix_bare_exceptions(file_path),
                self.fix_print_statements(file_path),
                self.fix_wildcard_imports(file_path),
                self.add_type_hints(file_path),
                self.add_docstrings(file_path)
            ]
            
            for fix_result in fixes:
                self.fix_results.append(fix_result)
                if fix_result.success:
                    successful_fixes += 1
                    total_fixes += fix_result.changes_made
        
        # Generate summary
        summary = {
            "total_files_processed": len(python_files),
            "total_fixes_applied": total_fixes,
            "successful_fixes": successful_fixes,
            "fix_results": self.fix_results,
            "fix_types": {
                "bare_exceptions": len([f for f in self.fix_results if f.fix_type == "bare_exceptions" and f.success]),
                "print_statements": len([f for f in self.fix_results if f.fix_type == "print_statements" and f.success]),
                "wildcard_imports": len([f for f in self.fix_results if f.fix_type == "wildcard_imports" and f.success]),
                "type_hints": len([f for f in self.fix_results if f.fix_type == "type_hints" and f.success]),
                "docstrings": len([f for f in self.fix_results if f.fix_type == "docstrings" and f.success])
            }
        }
        
        logger.info(f"âœ… Critical Fixes Phase 1 Complete!")
        logger.info(f"Total files processed: {summary['total_files_processed']}")
        logger.info(f"Total fixes applied: {summary['total_fixes_applied']}")
        logger.info(f"Successful fixes: {summary['successful_fixes']}")
        
        return summary
    
    def generate_report(self, summary: Dict[str, Any]) -> str:
        """Generate a report of the fixes applied"""
        report = f"""
# Critical Fixes Phase 1 Report

## Summary
- **Total Files Processed**: {summary['total_files_processed']}
- **Total Fixes Applied**: {summary['total_fixes_applied']}
- **Successful Fixes**: {summary['successful_fixes']}

## Fix Types Applied
"""
        
        for fix_type, count in summary['fix_types'].items():
            report += f"- **{fix_type.replace('_', ' ').title()}**: {count} files\n"
        
        report += "\n## Detailed Results\n"
        
        for result in self.fix_results:
            status = "âœ…" if result.success else "âŒ"
            report += f"- {status} {result.file_path}: {result.fix_type} ({result.changes_made} changes)\n"
            if not result.success and result.error_message:
                report += f"  - Error: {result.error_message}\n"
        
        report += f"\n## Backups Created\n"
        report += f"All original files backed up to: `{self.backup_dir}`\n"
        
        return report

def main() -> None:
    """Main function"""
    logging.info("ðŸ”§ Critical Fixes Phase 1 - AI Swarm Recommendations")
    logging.info("=" * 60)
    
    fixer = CriticalFixer()
    summary = fixer.apply_all_fixes()
    
    # Generate and save report
    report = fixer.generate_report(summary)
    report_path = Path("critical_fixes_phase1_report.md")
    with open(report_path, 'w') as f:
        f.write(report)
    
    logging.info(f"\nðŸ“„ Report saved to: {report_path}")
    logging.info(f"ðŸ’¾ Backups saved to: {fixer.backup_dir}")
    
    logging.info(f"\nðŸŽ‰ Phase 1 Complete!")
    logging.info(f"Applied {summary['total_fixes_applied']} critical fixes across {summary['total_files_processed']} files")
    
    return summary

if __name__ == "__main__":
    main() 